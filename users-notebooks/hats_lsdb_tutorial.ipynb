{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f154a7e-9526-4465-8d50-47923bce6faf",
   "metadata": {},
   "source": [
    "<img align='left' src = '../images/linea.png' width=150 style='padding: 20px'> \n",
    "\n",
    "# Tutorial: particionamento de dados no formato HATS e cross-matching com a biblioteca LSDB\n",
    "\n",
    "Passo-a-passo para conversão de catálogos astronômicos para o formato HATS e execução de cross-matching utilizando a biblioteca LSDB. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42279eae-692c-434c-9e8b-52b840357838",
   "metadata": {},
   "source": [
    "Contatos: Luigi Silva ([luigi.silva@linea.org.br](mailto:luigi.silva@linea.org.br)); Julia Gschwend ([julia@linea.org.br](mailto:julia@linea.org.br)).\n",
    "\n",
    "Última verificação: 27/08/2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c2368-84f4-4154-b46c-1776a6117208",
   "metadata": {},
   "source": [
    "\n",
    "#### Reconhecimentos\n",
    "\n",
    "'_Este notebook utilizou recursos computacionais da Associação Laboratório Interinstitucional de e-Astronomia (LIneA) com o apoio financeiro do INCT do e-Universo (Processo n.º 465376/2014-2)._' \n",
    "\n",
    "'_Este notebook se baseia nas bibliotecas e documentações do projeto LSST Interdisciplinary Network for Collaboration and Computing (LINCC) Frameworks, principalmente as bibliotecas hats, hats_import e lsdb. O projeto LINCC Frameworks é apoiado pelo Schmidt Sciences. Ele também é baseado em trabalhos apoiados pela National Science Foundation sob o Subsídio nº AST-2003196. Além disso, ele recebe apoio do DIRAC Institute do Departamento de Astronomia da Universidade de Washington. O DIRAC Institute é apoiado por meio de doações do Charles and Lisa Simonyi Fund for Arts and Sciences, e pelo Washington Research Foundation._'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65282a50-b754-4200-b2b9-5cb2a5af9ee8",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affba269-dc23-465b-b30a-40d2094bcf32",
   "metadata": {},
   "source": [
    "## Links de referência das bibliotecas de interesse principal\n",
    "\n",
    "Muitos dos textos contidos neste notebook foram extraídos, ou baseados, nos textos das documentações e repositórios das bibliotecas de interesse principal (hats, hats_import e lsdb). A seguir, temos os links para os repositórios e documentações destas bibliotecas. \n",
    "\n",
    "### Repositórios \n",
    "```lsdb```: https://github.com/astronomy-commons/lsdb <br>\n",
    "```hats_import```: https://github.com/astronomy-commons/hats-import <br>\n",
    "```hats```: https://github.com/astronomy-commons/hats\n",
    "\n",
    "### Documentações\n",
    "```lsdb```: https://lsdb.readthedocs.io/en/stable/ <br>\n",
    "```hats_import```: https://hats-import.readthedocs.io/en/stable/ <br>\n",
    "```hats```: https://hats.readthedocs.io/en/stable/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda036f3-ff4a-4650-951a-f06174c5644d",
   "metadata": {},
   "source": [
    "## HEALPix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6224f0d-779e-4a9f-b937-9e7219eb79c7",
   "metadata": {},
   "source": [
    "As bibliotecas hats, hats_import e lsdb utilizam o conceito do HEALPix.\n",
    "\n",
    "\"HEALPix é um acrônimo para Hierarchical Equal Area isoLatitude Pixelization de uma esfera. Como sugerido no nome, essa pixelização produz uma subdivisão de uma superfície esférica na qual cada pixel cobre a mesma área de superfície que todos os outros pixels. A figura abaixo mostra a partição de uma esfera em resoluções progressivamente mais altas, da esquerda para a direita. A esfera verde representa a menor resolução possível com a partição base do HEALPix da superfície esférica em 12 pixels de tamanho igual. A esfera amarela tem uma grade HEALPix de 48 pixels, a esfera vermelha tem 192 pixels e a esfera azul tem uma grade de 768 pixels (resolução de ~7,3 graus).\n",
    "\n",
    "<center> <img src=\"https://healpix.jpl.nasa.gov/images/healpixGridRefinement.jpg\" width=\"600\"> </center>\n",
    "\n",
    "Outra propriedade da grade HEALPix é que os centros dos pixels, representados pelos pontos pretos, ocorrem em um número discreto de anéis de latitude constante. O número de anéis de latitude constante depende da resolução da grade HEALPix. Para as esferas verde, amarela, vermelha e azul mostradas, há 3, 7, 15 e 31 anéis de latitude constante, respectivamente.\" ([HEALPix - NASA](https://healpix.jpl.nasa.gov/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88372051-cad6-4b91-994c-892f6df9415a",
   "metadata": {},
   "source": [
    "## HATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf54055-cfc5-4626-bbdc-5d687c7bca90",
   "metadata": {},
   "source": [
    "\"Um catálogo [HATS (Hierarchical Adaptive Tiling Scheme)](https://github.com/astronomy-commons/hats) é uma partição de objetos em uma esfera. Seu propósito é armazenar dados de grandes levantamentos astronômicos, mas provavelmente poderia ser usado para outros casos de uso onde se tenha grandes volumes de dados com algumas propriedades esféricas.\" ([HATS - GitHub](https://github.com/astronomy-commons/hats))\n",
    "\n",
    "#### Esquema de Particionamento\n",
    "\"Nos catálogos no formato HATS, é utilizado o HEALPix (Hierarchical Equal Area isoLatitude Pixelization) para a pixelização esférica e as partições são dimensionadas de forma adaptativa com base no número de objetos.\n",
    "\n",
    "Em áreas do céu com mais objetos, são usados pixels menores, de modo que todos os pixels resultantes contenham contagens similares de objetos (dentro de uma ordem de magnitude).\" ([HATS - Docs](https://hats.readthedocs.io/en/stable/guide/directory_scheme.html))\n",
    "\n",
    "#### Estrutura de Arquivos\n",
    "\"O leitor do catálogo espera encontrar arquivos de acordo com a seguinte estrutura particionada: \" ([HATS - Docs](https://hats.readthedocs.io/en/stable/guide/directory_scheme.html))\n",
    "\n",
    "```\n",
    "_ /path/to/catalogs/<catalog_name>/\n",
    "   |__ partition_info.csv\n",
    "   |__ properties\n",
    "   |__ dataset/\n",
    "       |__ _common_metadata\n",
    "       |__ _metadata\n",
    "       |__ Norder=1/\n",
    "       |   |__ Dir=0/\n",
    "       |       |__ Npix=0.parquet\n",
    "       |       |__ Npix=1.parquet\n",
    "       |__ Norder=J/\n",
    "           |__ Dir=10000/\n",
    "               |__ Npix=K.parquet\n",
    "               |__ Npix=M.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4a18c-2988-4001-8c45-d4082cb3d4ef",
   "metadata": {},
   "source": [
    "## Cross-matching espacial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c411b57-a8d3-47f8-87ce-0e029264673c",
   "metadata": {},
   "source": [
    "O cruzamento espacial, ou *cross-matching* espacial, entre diferentes catálogos astronômicos consiste em identificar e comparar objetos astronômicos de uma mesma região do céu, porém provenientes de diferentes observações.\n",
    "\n",
    "O *cross-matching espacial* entre diferentes catalógos é muito útil. Um exemplo desta utilidade pode ser encontrado na elaboração de conjuntos de treinamento para algoritmos de *machine learning* que calculam *redshifts* fotométricos. Esses conjuntos de treinamento podem ser elaborados a partir do cruzamento de objetos de um catálogo fotométrico (de onde serão extraídos os *features*) com objetos de um catálogo espectroscópico (de onde serão extraídos os nossos *true redshifts*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687a023-8766-4705-870a-86af2f13662e",
   "metadata": {},
   "source": [
    "### Escalabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f52b19-8c18-43e7-b401-086540291676",
   "metadata": {},
   "source": [
    "Com o grande volume de dados dos levantamentos atuais e futuros, como o [Rubin Observatory Legacy Survey of Space and Time (LSST)](https://rubinobservatory.org/explore/how-rubin-works/lsst), o armazenamento e manipulação destes dados é um grande desafio. Catálogos com bilhões de objetos e tamanho de vários terabytes são desafiadores de armazenar e manipular porque exigem hardware de última geração. Processá-los é caro, tanto em termos de tempo de execução quanto de consumo de memória, e realizá-lo em uma única máquina tornou-se impraticável. ([LSDB - Docs](https://docs.lsdb.io/en/stable/tutorials/filtering_large_catalogs.html))\n",
    "\n",
    "A biblioteca [LSDB (Large Survey DataBase)](https://github.com/astronomy-commons/lsdb) é uma solução que permite a execução escalável de algoritmos. Ele lida com carregamento, consulta, filtragem e cruzamento de dados astronômicos (no formato HATS) em um ambiente distribuído. O *framework* que permite essa escalabilidade, utilizado pelo LSDB, é o Dask, que aproveita as capacidades de computação distribuída. Com Dask, as operações definidas em um fluxo de trabalho são adicionadas a um gráfico de tarefas que otimiza sua ordem de execução. As operações não são imediatamente computadas - somos nós que decidimos quando iremos computá-las. Assim que iniciamos as computações, o Dask distribui a carga de trabalho entre seus vários *dask workers*, distribuídos entre os nós de um Cluster, por exemplo, e as tarefas são executadas de maneira eficiente em paralelo. ([LSDB - Docs](https://docs.lsdb.io/en/stable/tutorials/filtering_large_catalogs.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aac322-90ee-4886-bfe3-8f317ad3e99e",
   "metadata": {},
   "source": [
    "### Objetos nas bordas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719014fc-4207-4074-9202-c2b8766111f2",
   "metadata": {},
   "source": [
    "A biblioteca LSDB usa os catálogos no formato HATS como forma de organizar os dados espacialmente para, dentre outras coisas, conseguir carregar todos os pontos vizinhos de maneira simultânea, o que é essencial para comparações precisas. No entanto, há uma limitação: nas bordas de cada pixel, alguns pontos serão perdidos. Isso significa que, para operações que exigem comparações com pontos vizinhos, como o cruzamento de dados, o processo pode perder algumas correspondências para pontos próximos às bordas das partições, porque nem todos os pontos próximos são incluídos ao analisar uma partição de cada vez. ([LSDB Docs](https://lsdb.readthedocs.io/en/stable/tutorials/margins.html))\n",
    "\n",
    "<center> <img src=\"https://lsdb.readthedocs.io/en/stable/_images/pixel-boundary-example.png\" width=\"600\"> </center>\n",
    "<center><legend>Aqui vemos um exemplo de uma fronteira entre pixels HEALPix, onde os pontos verdes estão em uma partição e os pontos vermelhos em outra. Trabalhando com uma partição de cada vez, perderíamos correspondências potenciais com pontos próximos à fronteira. (<a href=\"https://lsdb.readthedocs.io/en/stable/tutorials/margins.html\">LSDB - Docs</a>) </legend></center> <br>\n",
    "\n",
    "Para resolver isso, poderíamos tentar carregar também as partições vizinhas para cada partição que cruzarmos. No entanto, isso significaria carregar muitos dados desnecessários, o que desaceleraria as operações e causaria problemas de falta de memória. Então, para cada catálogo, também criamos um cache de margem. Isso significa que, para cada partição, criamos um arquivo que contém os pontos no catálogo dentro de uma certa distância da borda do pixel. ([LSDB Docs](https://lsdb.readthedocs.io/en/stable/tutorials/margins.html))\n",
    "\n",
    "<center> <img src=\"https://lsdb.readthedocs.io/en/stable/_images/margin-pix.png\" width=\"600\"> </center>\n",
    "<center><legend>Um exemplo de um cache de margem (laranja) para o mesmo pixel anterior, em verde. O cache de margem para este pixel contém os pontos dentro de uma distância de 10 arcsec da fronteira. (<a href=\"https://lsdb.readthedocs.io/en/stable/tutorials/margins.html\">LSDB - Docs</a>) </legend></center> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0908f6-6218-4766-adf0-c100b6a9a5c8",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Importação das bibliotecas e configurações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42bc34-1373-4c25-bd2b-734b80f5f73c",
   "metadata": {},
   "source": [
    "Antes da instalação das bibiliotecas necessárias para esse notebook, é **recomendado criar um ambiente virtual**. Para isso, você pode seguir os passos contidos na documentação da biblioteca [LSDB](https://docs.lsdb.io/en/stable/getting-started.html) ou os passos do notebook de tutorial ```3-conda-env.ipynb``` contido no [repositório de tutorial do LIneA](https://github.com/linea-it/jupyterhub-tutorial). Após isso, para utilizar esse ambiente virtual como um kernel no Jupyter Notebook, são necessários os passos a seguir:\n",
    "\n",
    "<p style=\"background-color:black; color:white;\">\n",
    "    <font face=\"Courier New\">\n",
    "        conda install -c anaconda ipykernel \n",
    "    </font>\n",
    "</p>\n",
    "\n",
    "<p style=\"background-color:black; color:white;\">\n",
    "    <font face=\"Courier New\">\n",
    "        python -m ipykernel install --user --name=NOME-DO-SEU-AMBIENTE-VIRTUAL\n",
    "    </font>\n",
    "</p>\n",
    "\n",
    "Estes comandos vão fazer com que o ambiente criado seja disponibilizado como um kernel para o Jupyter Notebook.\n",
    "\n",
    "As instruções de instalação para as bibliotecas de interesse principal podem ser encontradas nas documentações do [LSDB](https://docs.lsdb.io/en/stable/getting-started.html) e do [HATS Import](https://hats-import.readthedocs.io/en/stable/).\n",
    "\n",
    "\n",
    "Requisitos para este notebook:\n",
    "\n",
    "* **Bibliotecas gerais**: os, sys, math, numpy, time, pathlib.\n",
    "* **Bibliotecas astronômicas:** astropy.\n",
    "* **Bibliotecas de computação paralela**: dask.\n",
    "* **Bibliotecas de visualização**: bokeh, holoviews, geoviews, datashader, matplotlib.\n",
    "* **Bibliotecas de interesse principal:** hats, hats_import, lsdb.\n",
    "* **Bibliotecas de manipulação de dados**: pandas.\n",
    "* **Bibliotecas para a obtenção de dados**: dblinea.\n",
    "\n",
    "* **Arquivo auxiliar**: [des-round19-poly.txt](https://github.com/kadrlica/skymap/blob/master/skymap/data/des-round19-poly.txt) (contorno da área coberta pelo levantamento do DES DR2, i.e., DES _footprint_, 2019 version).\n",
    "\n",
    "Precisamos fazer o download do arquivo `des-round19-poly.txt` do repositório [kadrlica/skymap](https://github.com/kadrlica/skymap) no GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ccca9-139f-47a1-84a9-c7caf910f5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/kadrlica/skymap/master/skymap/data/des-round19-poly.txt -O des-round19-poly.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e9438-33b4-42a1-9b15-061bdef00b80",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24386a-a32c-48aa-8df1-9d8040009c22",
   "metadata": {},
   "source": [
    "Vamos importar as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d607d-e239-4c09-93e3-41eb553e1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### GENERAL ######################\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f1b49-5533-468a-8e64-9a8562aed734",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### ASTRONOMY ######################\n",
    "### ASTROPY\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27e332-799f-44bc-b1ec-f15dd5990320",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### PARALLEL COMPUTING ######################\n",
    "### DASK\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161e74e-41aa-42a6-82f7-ab01b15391c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### VISUALIZATION ######################\n",
    "### BOKEH\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColorBar, LinearColorMapper\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "### HOLOVIEWS\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import rasterize, dynspread\n",
    "\n",
    "### GEOVIEWS\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from cartopy import crs\n",
    "\n",
    "### MATPLOTLIB\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd56ecd-8ba6-4bcd-b6af-9da81505d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### HATS AND LSDB ######################\n",
    "### HATS\n",
    "## Explore the HATS catalogs and plot sky maps\n",
    "import hats\n",
    "from hats.catalog import Catalog\n",
    "from hats.inspection import plot_pixels\n",
    "\n",
    "## For converting the data to HATS format and generate margin caches\n",
    "import hats_import\n",
    "from hats_import.catalog.file_readers import CsvReader\n",
    "from hats_import.margin_cache.margin_cache_arguments import MarginCacheArguments\n",
    "from hats_import.pipeline import ImportArguments, pipeline_with_client  \n",
    "\n",
    "### LDSB\n",
    "import lsdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56d44b-f3f0-40b1-8d56-e802e96d80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### DATA MANAGEMENT ######################\n",
    "### PANDAS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9deb390-2042-4cad-b1f8-f1cbb9f80aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### DATA ACCESS ######################\n",
    "### DB LIneA\n",
    "from dblinea import DBBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea42d57-bf5b-4020-99dd-731e8a283720",
   "metadata": {},
   "source": [
    "A seguir, são impressas as versões do Python, Numpy, Bokeh e Holoviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54659e8-f465-4b22-bbcd-56f681ddaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python version: ' + sys.version)\n",
    "print('Numpy version: ' + np.__version__)\n",
    "print('Bokeh version: ' + bokeh.__version__)\n",
    "print('HoloViews version: ' + hv.__version__)\n",
    "print('hats-import version: ' + hats_import.__version__)\n",
    "print('lsdb version: ' + lsdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317adad-9d3d-4a8a-a04b-09f6bb55de42",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ff60c-72a5-456d-a8bc-c9e3de8c5b6d",
   "metadata": {},
   "source": [
    "Definindo o cliente Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a7db2-19eb-4b77-9db6-2673d708b04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc5f1b-7c6b-4065-bcbf-3485c32be9d6",
   "metadata": {},
   "source": [
    "Definindo o número de linhas que o pandas irá exibir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa6492-7e2b-4200-a1cd-7274099dfc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b35cb-741e-460f-9dc4-9e54f9a230e0",
   "metadata": {},
   "source": [
    "Configurando o holoviews e o geoviews para trabalhar com o bokeh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab2838-c085-4438-9da2-37d952facb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e62d71-7c94-440f-85c8-0e9f094e86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf21dfd-cee2-4c21-b682-d082f1cc74b7",
   "metadata": {},
   "source": [
    "Configurando os plots do bokeh para serem em linha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff0bcf-209c-42a1-8fae-73bb1369d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686657b-f1b4-43b4-9d42-6d747a494cfc",
   "metadata": {},
   "source": [
    "Configurando os plots do matplotlib para serem em linha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39c7b1-b44c-455a-ac7d-dcf6bbc43a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b9cdd-8684-4e32-ad5a-048ecfcc44ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Leitura dos dados do footprint do DES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8ccdf-04ff-44b3-8ddc-275ce32f42c8",
   "metadata": {},
   "source": [
    "A seguir, vamos ler o footprint do DES DR2 do arquivo `des-round19-poly.txt` e imprimir os mínimos e máximos de R.A. e DEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a3ee5-f540-4187-8977-a0aecc6c96f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foot_ra, foot_dec = np.loadtxt('des-round19-poly.txt', unpack=True)\n",
    "\n",
    "print(\"R.A. AND DEC COORDINATES, BEFORE USING SKYCOORD\")\n",
    "print(f\"R.A. min: {foot_ra.min():.2f} | R.A. max: {foot_ra.max():.2f}\")\n",
    "print(f\"DEC min: {foot_dec.min():.2f} | DEC max: {foot_dec.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a12b7-dd68-43da-8338-5dca1900b338",
   "metadata": {},
   "source": [
    "Depois de ler o footprint, definimos a classe SkyCoord da biblioteca Astropy usando as coordenadas R.A. e DEC do footprint. Com o SkyCoord, temos uma interface flexível para representação, manipulação e transformação de coordenadas celestes entre sistemas. Usamos também o módulo de unidades do Astropy; em ```u.degree```, por exemplo, indicamos que as coordenadas estão em graus. Além disso, usamos o método ```wrap_at``` para garantir que as coordenadas estejam no intervalo $[-180,180)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e996a-61dc-4ee2-86d4-eaa5a6095dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foot_coords = SkyCoord(ra=foot_ra*u.degree, dec=foot_dec*u.degree, frame='icrs')\n",
    "foot_df = pd.DataFrame({'foot_ra': np.array(foot_coords.ra.wrap_at(180*u.degree)), \n",
    "                        'foot_dec': np.array(foot_coords.dec)})\n",
    "\n",
    "print(\"R.A. AND DEC COORDINATES, AFTER USING SKYCOORD\")\n",
    "print(f\"R.A. min: {foot_df['foot_ra'].min():.2f} | R.A. max: {foot_df['foot_ra'].max():.2f}\")\n",
    "print(f\"DEC min: {foot_df['foot_dec'].min():.2f} | DEC max: {foot_df['foot_dec'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23a8de-e171-4cfc-abae-a1ab2d503aa5",
   "metadata": {},
   "source": [
    "## Função para gerar os gráficos de distribuição espacial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede416f-8fe0-4b4f-a798-797c9f4bb38e",
   "metadata": {},
   "source": [
    "A seguir, temos uma função que retorna os gráficos de distribuição espacial, dadas as coordenadas R.A. e DEC dos objetos. Essa função será usada posteriormente nos plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a2d1c-2643-4990-87fb-fe92ad566016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spatial_distribution(ra_coords, dec_coords, title, \n",
    "                              longitudes_ticks=np.arange(30, 360, 30), \n",
    "                              latitudes_ticks=np.arange(-75, 76, 15),\n",
    "                              height=500, width=1000, padding=0.05,\n",
    "                              xlabel='R.A.', ylabel='DEC', \n",
    "                              show_des_footprint=True, \n",
    "                              show_grid=True, \n",
    "                              show_labels=True):\n",
    "    '''Função para exibir os gráficos de distribuição espacial de objetos.\n",
    "        \n",
    "        Argumentos:\n",
    "        ra_coords (pandas.core.series.Series, numpy.ndarray ou list): coordenadas R.A. do objeto, em graus.\n",
    "        dec_coords (pandas.core.series.Series, numpy.ndarray ou list): coordenadas DEC do objeto, em graus.\n",
    "        title (str): título a ser exibido no gráfico.\n",
    "        longitudes_ticks (numpy.ndarray): ticks de longitude a serem exibidos no gráfico. PADRÃO: np.arange(30, 360, 30)\n",
    "        latitudes_ticks (numpy.ndarray): ticks de latitude a serem exibidos no gráfico. PADRÃO: np.arange(-75, 76, 15)\n",
    "        height (float): parâmetro relacionado às dimensões do plot. PADRÃO: 500\n",
    "        width (float): parâmetro relacionado às dimensões do plot. PADRÃO: 1000\n",
    "        padding (float): parâmetro relacionado ao posicionamento do plot. PADRÃO: 0.05\n",
    "        xlabel (str): nome do eixo-x. PADRÃO: 'R.A.'\n",
    "        ylabel (str): nome do eixo-y. PADRÃO: 'DEC'\n",
    "        show_des_footprint (boolean): se mostra ou não o footprint do DES. PADRÃO: True\n",
    "        show_grid (boolean): se mostra ou não as linhas de grid. PADRÃO: True\n",
    "        show_labels (boolean): se mostra ou não os ticks de latitude e longitude. PADRÃO: True\n",
    "    '''\n",
    "    \n",
    "    ### Definindo os ticks de R.A. e DEC. para os plots.\n",
    "    longitudes = longitudes_ticks\n",
    "    latitudes = latitudes_ticks\n",
    "\n",
    "    lon_labels = [f\"{lon}°\" for lon in longitudes]\n",
    "    lat_labels = [f\"{lat}°\" for lat in latitudes]\n",
    "\n",
    "    labels_data = {\n",
    "        \"lon\": list(np.flip(longitudes)) + [-180] * len(latitudes),\n",
    "        \"lat\": [0] * len(longitudes) + list(latitudes),\n",
    "        \"label\": lon_labels + lat_labels,\n",
    "    }\n",
    "\n",
    "    df_labels = pd.DataFrame(labels_data)\n",
    "\n",
    "    labels_plot = gv.Labels(df_labels, kdims=[\"lon\", \"lat\"], vdims=[\"label\"]).opts(\n",
    "        text_font_size=\"12pt\",\n",
    "        text_color=\"black\",\n",
    "        text_align='right',\n",
    "        text_baseline='bottom',\n",
    "        projection=crs.Mollweide()\n",
    "    )\n",
    "\n",
    "    ### Definindo as linhas de grid.\n",
    "    grid = gf.grid()\n",
    "\n",
    "    ### Definindo a curva do footprint do DES.\n",
    "    ### Aqui, multiplicamos as coordenadas 'ra' por (-1) para que o plot fique invertido em R.A. Essa é uma convenção muito utilizada.\n",
    "    ra_dec_foot = gv.Path(((-1)*foot_df['foot_ra'], foot_df['foot_dec'])).opts(line_width=3, color='orange')\n",
    "\n",
    "    ### Definindo a classe SkyCoord do astropy para manipulação das coordenadas astronômicas.\n",
    "    ra_dec_coords = SkyCoord(ra=np.array(ra_coords)*u.degree, dec=np.array(dec_coords)*u.degree, frame='icrs')\n",
    "\n",
    "    ### Usando o método wrap_at para garantir que as coordenadas estejam no intervalo [-180, 180).\n",
    "    ra_dec_coords = pd.DataFrame({'ra_coords': np.array(ra_dec_coords.ra.wrap_at(180*u.degree)), \n",
    "                                  'dec_coords': np.array(ra_dec_coords.dec)})\n",
    "\n",
    "    ### Definindo o objeto points do geoviews.\n",
    "    ### Novamente, multiplicamos as coordenadas 'ra' por (-1) para que o plot fique invertido em R.A. Essa é uma convenção muito utilizada.\n",
    "    ra_dec_points = gv.Points(((-1)*ra_dec_coords['ra_coords'], ra_dec_coords['dec_coords']), kdims=['ra', 'dec'])\n",
    "\n",
    "    ### Aplicando a projeção Mollweide.\n",
    "    projected = gv.operation.project(ra_dec_points, projection=crs.Mollweide())\n",
    "\n",
    "    ### Aplicando o datashader sobre os pontos.\n",
    "    dsh_points = dynspread(rasterize(projected).opts(cmap=\"Viridis\", cnorm='log'))\n",
    "    dsh_points = dsh_points.opts(width=width, height=height, padding=padding, title=title, toolbar='above', colorbar=True, tools=['box_select'])\n",
    "\n",
    "    ### Exibindo o plot.\n",
    "    if show_des_footprint==True:\n",
    "        return(dsh_points * ra_dec_foot * grid * labels_plot)\n",
    "    elif show_grid==True:\n",
    "        return(dsh_points * grid * labels_plot)\n",
    "    elif show_labels==True:\n",
    "        return(dsh_points * labels_plot)\n",
    "    else:\n",
    "        return(dsh_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91cf677-0c33-4063-a9e3-02115a447cf0",
   "metadata": {},
   "source": [
    "# Caracterização da amostra espectroscópica de exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb45e7-8b12-4861-aca4-c6510c3ec638",
   "metadata": {},
   "source": [
    "Para executar o cross-matching posteriormente, **usaremos como dados espectroscópicos uma amostra de objetos do 2dFLenS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb395fd8-7b2e-40c3-822a-a89e2d79e958",
   "metadata": {},
   "source": [
    "|Nome do levantamento <br> (link para o website)| Número de **redshifts** na <br>amostra original | Referência <br> (link para o artigo) |\n",
    "|---|:-:|---|\n",
    "|[2dFLenS](http://2dflens.swin.edu.au/) |70,079| [Blake et al. 2016](https://ui.adsabs.harvard.edu/abs/2016MNRAS.462.4240B/abstract)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e12f06-1738-4953-8d09-5947f005fa5a",
   "metadata": {},
   "source": [
    "A amostra que será utilizada será extraída de uma tabela chamada **public_specz_compilation** via biblioteca DBLIneA. Essa tabela contém um compilado de catálogos de diferentes levantamentos, os quais foram coletados ao longo dos anos de operação do Dark Energy Survey (DES) e agrupados sistematicamente pela ferramenta DES Science Portal (pipeline Spectroscopic Sample) para formar a base de um conjunto de treinamento para algoritmos de cálculo de *redshifts* fotométricos baseados em machine learning. Temos, no total, dados de 28 levantamentos, como 2DF, 2dFLenS, 3DHST, 6DF, etc.\n",
    "\n",
    "A seguir, podemos ver as 5 primeiras linhas desse compilado de *redshifts* fotométricos, a estatística básica dos dados e um plot simples de sua distribuição espacial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aad126-4acb-41b9-bb5d-c002926e9262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = DBBase()\n",
    "schema = 'des_dr2'  \n",
    "tablename = 'public_specz_compilation'\n",
    "\n",
    "query = f'SELECT * FROM {schema}.{tablename}'\n",
    "specz_compilation_data = db.fetchall_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f8aee-5d3c-44a9-8d19-82a3a4243a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specz_compilation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b858b-ea4d-42e9-a8bb-a50997ff1945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specz_compilation_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5fdda-789c-4a40-a154-9553207c16e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra_coords = specz_compilation_data['ra']\n",
    "dec_coords = specz_compilation_data['dec']\n",
    "title = 'Distribuição espacial - Todos os objetos contidos na tabela Public spec-z compilation'\n",
    "\n",
    "plot_spatial_distribution(ra_coords, dec_coords, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143ef96-719c-410e-83b1-640cebb4b807",
   "metadata": {},
   "source": [
    "**Observação: pode acontecer um bug de reenderização nos plots que subestime/superestime os objetos por pixel. Um simples clique na ferramenta \"reset\", na barra de ferramentas do Bokeh na parte superior do plot, deve resolver o problema. Se não resolver, certifique-se de que todos os pacotes e extensões foram instaladas corretamente, de forma que os gráficos estejam dinâmicos (reenderizam conforme o zoom dado). Em caso de dúvida, verifique o arquivo de instruções ```instructions_hispcat_lsdb_tutorial.md```, que está no mesmo diretório deste notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57893ae0-2192-47df-b0d5-8b28bd8610a5",
   "metadata": {},
   "source": [
    "Além de combinar todos os catálogos em uma única tabela, o _pipeline_ Spectroscopic Sample também homogeneiza as várias flags de qualidade originais dos catálogos em um único sistema (`flag_des`) baseado nos parâmetros usados no levantamento OzDES ([Yuan et al., 2015](https://ui.adsabs.harvard.edu/abs/2015MNRAS.452.3047Y/abstract)). Em resumo, as flags significam:\n",
    "\n",
    "|flag_des| Significado |\n",
    "|--- |---|\n",
    "|1 | redshift desconhecido |\n",
    "|2 | palpite não confiável |\n",
    "|3 | 95% de confiança |\n",
    "|4 | 99% de confiança |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60575da1-3fc0-4eaa-bcdc-8f126b6a87fc",
   "metadata": {},
   "source": [
    "Como a tabela **public_specz_compilation** contém um compilado de *redshifts* espectroscópicos de vários levantamentos astronômicos, muitos desses levantamentos observaram regiões comuns do céu. Ao agrupar todas as medidas em um catálogo único, geralmente há medidas múltiplas de *redshift* espectroscópico para um mesmo objeto. Para identificar esses casos, o *pipeline* Spectroscopic Sample fez uma combinação espacial entre as coordenadas equatoriais de \"todos contra todos\" com um raio de busca de 1.0 *arcsec* de cada objeto. Então, ele aplicou uma seleção para manter apenas uma medida para cada objeto extragaláctico presente na amostra, seguindo o critério abaixo para escolha e desempate:\n",
    "\n",
    "1. medida com a maior _flag_ de qualidade (`flag_des`)\n",
    "2. medida com o menor erro no *redshift* (`err_z`)\n",
    "3. medida obtida pelo levantamento mais recente\n",
    "\n",
    "Um corte de qualidade também foi aplicado onde apenas objetos com flag_des ⩾ 3 foram incluídos no compilado.\n",
    "\n",
    "\n",
    "Portanto, como a amostra do 2dFLenS que usaremos será um **subconjunto dos dados** contidos na tabela **public spec-z compilation**, estamos pegando, nessa amostra, **apenas aqueles objetos que permaneceram após a seleção considerando todos os outros catálogos presentes no compilado de *redshifts* fotométricos, e apenas os objetos com flag_des ⩾ 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e807e6-571c-4522-92ea-356586349119",
   "metadata": {},
   "source": [
    "## Todos os objetos do 2dFLenS, contidos no produto Public spec-z compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21eafb-86e6-496c-9f13-709418232fb2",
   "metadata": {},
   "source": [
    "Primeiramente, vamos filtrar os dados do compilado para obter apenas aqueles referentes ao 2dFLenS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ae0c1-e5b7-44d2-9e8f-0ee4f9b35c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample = specz_compilation_data[specz_compilation_data['survey']=='2dFLenS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af477b-98b5-46fd-a519-dc495749e245",
   "metadata": {},
   "source": [
    "A seguir, temos as primeiras 5 linhas da tabela contendo a amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c7077-c5a7-45d3-aa11-49500d3a595d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6fdfc-5e12-4fee-824f-9d55d70907bd",
   "metadata": {},
   "source": [
    "Temos também as estatísticas básicas dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535d109-ac55-41e1-bbe3-540bc93fa917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afebf5-5bed-4497-bfb3-fe2203be4c9e",
   "metadata": {},
   "source": [
    "Em seguida, fazemos o plot de distribuição de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08cb612-f7de-4c22-ad5e-0ceb338fa14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra_coords = df_specz_sample['ra']\n",
    "dec_coords = df_specz_sample['dec']\n",
    "title = 'Distribuição espacial - Todos os objetos do 2dFLenS, contidos na tabela Public spec-z compilation'\n",
    "\n",
    "plot_spatial_distribution(ra_coords, dec_coords, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ea583-b00a-4782-955c-d9731236250c",
   "metadata": {},
   "source": [
    "**Observação: pode acontecer um bug de reenderização nos plots que subestime/superestime os objetos por pixel. Um simples clique na ferramenta \"reset\", na barra de ferramentas do Bokeh na parte superior do plot, deve resolver o problema. Se não resolver, certifique-se de que todos os pacotes e extensões foram instaladas corretamente, de forma que os gráficos estejam dinâmicos (reenderizam conforme o zoom dado). Em caso de dúvida, verifique o arquivo de instruções ```instructions_hispcat_lsdb_tutorial.md```, que está no mesmo diretório deste notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb578764-9666-4014-a16a-d9a63ef22011",
   "metadata": {},
   "source": [
    "## Objetos do 2dFLenS filtrados para pertencerem ao footprint do DES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595641f-726e-4ad8-a12f-56328d8b6a9d",
   "metadata": {},
   "source": [
    "A seguir, faremos um filtro simples para obter os dados do 2dFLenS dentro do footprint do DES. O filtro a seguir irá guardar objetos com $ra<90$ ou $ra>359$, e $dec < -15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d75b6e-cc5b-4417-8c89-933b846f0f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample_filtered = df_specz_sample.query(\"ra > 359 | ra < 90. & dec < -15.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be57fe7-bb3b-4133-b9ce-b8c54dba9351",
   "metadata": {},
   "source": [
    "Mostrando as primeiras 5 linhas da tabela contendo a amostra filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333593c-4d38-4e55-9b48-2fbd834335e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9210193-9bcd-44c4-9504-59b77e2953b0",
   "metadata": {},
   "source": [
    "Estatística básica desses dados filtrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18664-7fbf-4626-8ca5-2af2ee0272ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_specz_sample_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6458d52-1eaf-47d6-8361-13a2ccba5ade",
   "metadata": {},
   "source": [
    "Em seguida, fazemos o plot de distribuição de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa777f-1d77-4b10-8e85-b9faef5cf40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra_coords = df_specz_sample_filtered['ra']\n",
    "dec_coords = df_specz_sample_filtered['dec']\n",
    "title = 'Distribuição espacial - Objetos do 2dFLenS filtrados para pertencerem ao footprint do DES'\n",
    "\n",
    "plot_spatial_distribution(ra_coords, dec_coords, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255700ee-80a1-4411-915c-8f421fdd45d9",
   "metadata": {},
   "source": [
    "**Observação: pode acontecer um bug de reenderização nos plots que subestime/superestime os objetos por pixel. Um simples clique na ferramenta \"reset\", na barra de ferramentas do Bokeh na parte superior do plot, deve resolver o problema. Se não resolver, certifique-se de que todos os pacotes e extensões foram instaladas corretamente, de forma que os gráficos estejam dinâmicos (reenderizam conforme o zoom dado). Em caso de dúvida, verifique o arquivo de instruções ```instructions_hispcat_lsdb_tutorial.md```, que está no mesmo diretório deste notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924171b8-b137-4f14-b9bc-a8ff6d45f3e0",
   "metadata": {},
   "source": [
    "Por fim, salvamos os dados em um arquivo. Antes de salvar, no entanto, resetamos os índices para que eles sejam inteiros sequenciais, para que possamos executar o cross-matching posteriormente. Os índices originais da tabela serão salvos na coluna \"index\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c3fdf-b67a-4318-bb73-b4c8861078a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! mkdir -p data/input\n",
    "! mkdir -p data/input/specz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba36f6-ec3b-4ffc-9e98-31c5d097967d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Resetando os índices.\n",
    "df_specz_sample_filtered_reseted = df_specz_sample_filtered.reset_index()\n",
    "\n",
    "df_specz_sample_filtered_reseted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff9a0e-64d7-4225-b907-37d980a689e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Salvando o arquivo.\n",
    "df_specz_sample_filtered_reseted.to_parquet('data/input/specz/specz-2dflens-sample.pq', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f7cee-60ae-4053-8818-c87ef720fa5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Caracterização da amostra fotométrica de exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecfeb48-6244-48cb-b647-fa2d90882716",
   "metadata": {},
   "source": [
    "Para executar o cross-matching posteriormente, **usaremos como dados fotométricos uma amostra de objetos do DES DR2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c15a9-6037-4d21-8dbb-9e0b89c00d9f",
   "metadata": {},
   "source": [
    "|Nome do levantamento <br> (link para o website)| Número de objetos na <br>tabela original | Referência <br> (link para o artigo) |\n",
    "|---|:-:|---|\n",
    "|[DES DR2](https://des.ncsa.illinois.edu/releases/dr2)|~691 milhões de objetos astronômicos distintos|[DES Collaboration 2021](https://arxiv.org/abs/2101.05765)| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef67a17-cc4e-4dd6-b665-252b9ebb9099",
   "metadata": {},
   "source": [
    "Para obter esses dados, utilizaremos a biblioteca ```dblinea```. Aqui, nós vamos acessar os dados da tabela **coadd_objects** do catálogo **DES DR2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e348ed5-a034-4469-9c17-854e4ab30f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = \"des_dr2\"  \n",
    "tablename = \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2483ac-41bb-4483-8e9f-d2c00922bedf",
   "metadata": {},
   "source": [
    "A tabela original tem 215 colunas. O nome e significado de cada coluna pode ser encontrado [aqui](https://des.ncsa.illinois.edu/releases/dr2/dr2-products/dr2-schema). Aqui, iremos utilizar as seguintes colunas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396d27a-607c-4ff7-80e9-53789d4e199e",
   "metadata": {},
   "source": [
    "| Coluna | Significado |\n",
    "|---|---|\n",
    "| COADD_OBJECT_ID | Identificador único para os objetos co-adicionados |\n",
    "| RA | Ascensão reta, com precisão quantizada para indexação (ALPHAWIN_J2000 tem precisão total, mas não indexada) [graus] |\n",
    "| DEC | Declinação, com precisão quantizada para indexação (DELTAWIN_J2000 tem precisão total, mas não indexada) [graus] |\n",
    "| MAG_AUTO_{G,R,I,Z,Y}_DERED | Estimativa de magnitude desavermelhada (usando SFD98), para um modelo elíptico baseado no raio de Kron [mag] |\n",
    "| MAGERR_AUTO_{G,R,I,Z,Y} | Incerteza na estimativa de magnitude, para um modelo elíptico baseado no raio de Kron [mag] |\n",
    "| FLAGS_{G,R,I,Z,Y} | *Flag* aditiva que descreve conselhos preventivos sobre o processo de extração da fonte. Use menos de 4 para objetos bem comportados |\n",
    "| EXTENDED_CLASS_COADD | 0: estrelas de alta confiança; 1: estrelas candidatas; 2: principalmente galáxias; 3: galáxias de alta confiança; -9: Sem dados; Usando fotometria Sextractor |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0a4bc-7249-4818-a375-604730a4c90c",
   "metadata": {},
   "source": [
    "Além disso, a tabela original tem muitos dados. Seria inviável, em termos computacionais, pegar todos os dados que coincidem com a região do 2dFLenS neste notebook. Portanto, iremos restringir a busca para uma região pequena. Aqui, usaremos a região com $7 < R.A < 10$ e $-33 < DEC < -30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c057c-a13c-44a4-a541-e347bdeada37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definindo as coordenadas para a query. Essas variáveis também serão usadas posteriormente nos plots.\n",
    "ra_min = 7\n",
    "ra_max = 10\n",
    "dec_min = -33\n",
    "dec_max = -30\n",
    "\n",
    "### Executando a query.\n",
    "query = (f\"SELECT coadd_object_id, ra, dec, mag_auto_g_dered, mag_auto_r_dered, mag_auto_i_dered, mag_auto_z_dered, mag_auto_y_dered, magerr_auto_g, \"+\n",
    "         f\"magerr_auto_r, magerr_auto_i, magerr_auto_z, magerr_auto_y, flags_g, flags_r, flags_i, flags_z, flags_y, extended_class_coadd \"+ \n",
    "         f\"FROM {schema}.{tablename} \"+\n",
    "         f\"WHERE (dec <= {dec_max} AND dec >= {dec_min} AND ra <= {ra_max} AND ra>={ra_min}) \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02be453-83b9-4827-ac40-db6211e4307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_photo_sample = db.fetchall_df(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4abd3-48d6-4874-b19d-ca6d91760535",
   "metadata": {},
   "source": [
    "A seguir, temos as primeiras cinco linhas da tabela contendo a amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df949a4f-eded-4a1a-981b-04d83585a394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_photo_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c683b-66e6-46ef-bc44-7a953ba7a097",
   "metadata": {},
   "source": [
    "Temos também as statísticas básicas dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44436669-1a3f-4141-b7a8-a7e2e415b59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_photo_sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04734209-bd76-46d1-a1b0-2ef15e9ba2e5",
   "metadata": {},
   "source": [
    "A seguir, fazemos um plot da distribuição espacial desses objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38c2fc-7093-4385-82f9-7b3513f6040e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra_coords = df_photo_sample['ra']\n",
    "dec_coords = df_photo_sample['dec']\n",
    "title = 'Distribuição espacial - Amostra do DES DR2'\n",
    "\n",
    "plot_spatial_distribution(ra_coords, dec_coords, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af345969-96aa-43fc-837a-5feb9c4639d8",
   "metadata": {},
   "source": [
    "**Observação: pode acontecer um bug de reenderização nos plots que subestime/superestime os objetos por pixel. Um simples clique na ferramenta \"reset\", na barra de ferramentas do Bokeh na parte superior do plot, deve resolver o problema. Se não resolver, certifique-se de que todos os pacotes e extensões foram instaladas corretamente, de forma que os gráficos estejam dinâmicos (reenderizam conforme o zoom dado). Em caso de dúvida, verifique o arquivo de instruções ```instructions_hispcat_lsdb_tutorial.md```, que está no mesmo diretório deste notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae511ef-229a-4643-918a-1b8018768a03",
   "metadata": {},
   "source": [
    "Por fim, salvamos os dados em um arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267cbcd-0e30-454d-8ddc-bdb1226efa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! mkdir -p data/input\n",
    "! mkdir -p data/input/photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a551b8d-c6dc-4206-9ce2-f75bfac23153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photo_sample.to_parquet('data/input/photo/photo-des-dr2-sample.pq', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c2bd9-bd39-4d5f-a9f9-48b8eb38a019",
   "metadata": {},
   "source": [
    "# Utilizando o `hats_import`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac3d0c2-215a-44cb-8dd6-9808c30e14b1",
   "metadata": {},
   "source": [
    "A biblioteca ```hats_import``` é um utilitário para converter grandes volumes de dados de levantamentos astronômicos para a estrutura HATS. A seguir, iremos utilizá-la para converter os dados espectroscópicos e fotométricos para o formato HATS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbd175-d508-4beb-a1cb-8f00d266f42e",
   "metadata": {},
   "source": [
    "## Instalação do `hats_import` \n",
    "\n",
    "A biblioteca hats_import normalmente pode ser instalada via pip com o comando:\n",
    "\n",
    "```shell\n",
    "pip install hats-import\n",
    "\n",
    "```\n",
    "\n",
    "Para mais detalhes sobre a instalação, veja a documentação [neste link](https://hats-import.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928e14c-32e9-4769-9edf-2ce74bf384f7",
   "metadata": {},
   "source": [
    "## Conversão para o formato HATS dos dados espectroscópicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a697b-a5ee-409c-8dc9-0534db7e351a",
   "metadata": {},
   "source": [
    "Para os passos a seguir, foram utilizados, principalmente, os seguintes exemplos de referência: <br>\n",
    "https://lsdb.readthedocs.io/en/stable/tutorials/pre_executed/des-gaia.html <br>\n",
    "https://hats-import.readthedocs.io/en/stable/catalogs/public/sdss.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685ee3f-dca7-4b6a-9a25-8870a5e508e5",
   "metadata": {},
   "source": [
    "Primeiramente, vamos ler o arquivo Parquet que salvamos para conferir a estrutura da tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b945a-34eb-407c-a7bf-c94375fe5909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(\"data/input/specz/specz-2dflens-sample.pq\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35043f72-49b5-47ce-9df0-2055aa4e08cb",
   "metadata": {},
   "source": [
    "Agora, vamos definir os diretórios para salvar os dados no formato HATS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15066a08-073a-4682-8d37-f533337ccd13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! mkdir -p data/hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5c768-5ffd-4158-b8a0-03ca496d3bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diretório dos dados espectroscópicos de input.\n",
    "_2DFLENS_DIR = Path(\"data/input/specz/\")\n",
    "\n",
    "### Nomes para os diretórios do catalógo e do cache de margem dos dados espectroscópicos no formato HATS.\n",
    "_2DFLENS_HATS_NAME = \"_2dflens\"\n",
    "_2DFLENS_MARGIN_CACHE_NAME = \"_2dflens_margin_cache\"\n",
    "\n",
    "### Definindo os diretórios para os arquivos HATS com base nos nomes definidos anteriormente.\n",
    "HATS_DIR = Path(\"data/hats/\")\n",
    "_2DFLENS_HATS_DIR = HATS_DIR / _2DFLENS_HATS_NAME\n",
    "_2DFLENS_MARGIN_CACHE_DIR = HATS_DIR / _2DFLENS_MARGIN_CACHE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a399ef-9797-414d-a703-a5bc03b24486",
   "metadata": {},
   "source": [
    "Vamos, então, converter os dados espectroscópicos para o formato HATS. Para isso, precisamos indicar para o pipeline as colunas contendo os IDs dos objetos, as coordenadas R.A. e DEC, o arquivo de input e o tipo deste arquivo (no nosso caso, um arquivo Parquet) e o nome e o diretório do catálogo HATS de output. \n",
    "\n",
    "Além disso, ao criar um novo catálogo utilizando o ```hats_import```, o pipeline tenta criar partições com aproximadamente o memso número de linhas por partição. Esse processo não é perfeito, porém, mesmo assim, o pipeline tenta criar pixels de área menor em áreas mais densas e pixels de área maior em áreas menos densas.\n",
    "\n",
    "O argumento pixel_threshold é usado para indicar até que ponto o pipeline deve dividir uma certa partição. Ele irá dividir a partição em pixels HEALPix cada vez menores até que o número de linhas fique menor que o pixel_theshold, parando o processo. O processo também pode parar caso hajam tantas divisões que ultrapassem o parâmetro ```highest_healpix_order``` (você pode conferir a ordem máxima padrão [neste link](https://hats-import.readthedocs.io/en/stable/autoapi/hats_import/catalog/arguments/index.html#hats_import.catalog.arguments.ImportArguments.highest_healpix_order)). Se for preciso dividir ainda mais, surgirá um erro na etapa \"Binning\" e os parâmetros devem ser ajustados.\n",
    "\n",
    "Para mais detalhes, [veja a documentação](https://hats-import.readthedocs.io/en/stable/catalogs/arguments.html).\n",
    "\n",
    "Convertendo os dados para o formato hats (**DESCOMENTE A ÚLTIMA LINHA PARA RODAR O PIPELINE**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7376a1-62f4-44c3-a1e5-06aca2414457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_2dflens_args = ImportArguments(\n",
    "    sort_columns=\"index\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    input_path=_2DFLENS_DIR,\n",
    "    file_reader=\"parquet\",\n",
    "    output_artifact_name=_2DFLENS_HATS_NAME,\n",
    "    output_path=HATS_DIR,\n",
    "    pixel_threshold=1_000,\n",
    ")\n",
    "\n",
    "### RUN THE PIPELINE (it will fail if the HATS catalog already exists) \n",
    "pipeline_with_client(_2dflens_args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19063d4d-0480-4054-b49c-2f2e96dc8e90",
   "metadata": {},
   "source": [
    "Fazendo o plot dos pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7008e-555b-4442-a17f-60f4f468f76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the HATS catalog metadata, it does not load any data, just healpix pixels and other metadata\n",
    "_2dflens_hats_catalog = hats.read_hats(_2DFLENS_HATS_DIR)\n",
    "plot_pixels(_2dflens_hats_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd5ecd-410c-4266-b8d8-f702ae26cc96",
   "metadata": {},
   "source": [
    "Posteriormente, desejamos fazer o cross-matching desses dados espectrocópicos (2dFLenS) no formato HATS com os dados fotométricos (DES DR2).\n",
    "\n",
    "O cross-matching, executado pela biblioteca LSDB, não é simétrico, o que significa que a escolha de qual catálogo é o \"esquerdo\" e qual é o \"direito\" é crucial. No nosso caso, iremos fazer o cross-matching do DES DR2 (esquerdo) com o 2dFLenS (direito). Essa configuração geralmente permite que múltiplos objetos DES sejam correspondidos a um único objeto do 2dFLenS, um resultado dos caches de margem. Os caches de margem são projetados para evitar a perda de objetos próximos às bordas dos tiles HEALPix. No entanto, eles podem levar a múltiplas correspondências, onde o mesmo objeto do 2dFLenS pode corresponder a um objeto DES em uma partição e a outro objeto DES na partição vizinha que inclui esse objeto do 2dFLenS em seu cache de margem.\n",
    "\n",
    "Portanto, para o cross-matching, a biblioteca LSDB precisa do cache de margem do catálogo direito para gerar o resultado completo do cruzamento. Sem o cache de margem, os objetos localizados perto das bordas dos tiles Healpix podem ser perdidos no cruzamento. Veja mais detalhes [neste link]( https://lsdb.readthedocs.io/en/stable/tutorials/pre_executed/des-gaia.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e81a2-1df5-4c02-b65d-8c03b63fc2a1",
   "metadata": {},
   "source": [
    "Gerando o cache de margem para o 2dFLenS (**DESCOMENTE A ÚLTIMA LINHA PARA RODAR O PIPELINE**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589823f6-8dc6-49c4-8e20-dd710fa4b606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "margin_cache_args = MarginCacheArguments(\n",
    "    input_catalog_path=_2DFLENS_HATS_DIR,\n",
    "    output_path=HATS_DIR, \n",
    "    margin_threshold=5.0,  # arcsec\n",
    "    output_artifact_name=_2DFLENS_MARGIN_CACHE_NAME,\n",
    ")\n",
    "\n",
    "### RUN THE PIPELINE (it will fail if the margin cache already exists) \n",
    "pipeline_with_client(margin_cache_args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6f0a2-c8ab-4a56-a76d-4aa12f1c58e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conversão para o formato hats dos dados fotométricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b162c4-e77a-47b5-b0c6-8b64a9663141",
   "metadata": {},
   "source": [
    "Para os passos a seguir, foram utilizados, principalmente, os seguintes exemplos de referência: <br>\n",
    "https://lsdb.readthedocs.io/en/stable/tutorials/pre_executed/des-gaia.html <br>\n",
    "https://hats-import.readthedocs.io/en/stable/catalogs/public/sdss.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054914a-5b53-453b-a68f-86e25fb701ab",
   "metadata": {},
   "source": [
    "Primeiramente, vamos ler o arquivo Parquet que salvamos para conferir a estrutura da tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7747cd-2169-4e18-bc56-ae698abd7fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(\"data/input/photo/photo-des-dr2-sample.pq\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f196d7-3c73-4c72-9a49-5fc2f69b18da",
   "metadata": {},
   "source": [
    "Agora, vamos definir os diretórios para salvar os dados no formato HATS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323a4ff-9279-427b-8c44-d6b6f2deac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! mkdir -p data/hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb28f4-795a-4fcb-83f0-74368a6015a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diretório dos dados fotométricos de input.\n",
    "DES_DIR = Path(\"data/input/photo/\")\n",
    "\n",
    "### Nome para o diretório do catalógo dos dados fotométricos no formato HATS.\n",
    "DES_HATS_NAME = \"des_dr2\"\n",
    "\n",
    "### Definindo o diretório para os arquivos HATS com base no nome definido anteriormente.\n",
    "HATS_DIR = Path(\"data/hats/\")\n",
    "DES_HATS_DIR = HATS_DIR / DES_HATS_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935746ed-d40a-40fc-b2ac-b085a42dadde",
   "metadata": {},
   "source": [
    "Da mesma forma que foi feito para os dados espectroscópicos, vamos, a seguir, converter os dados fotométricos para o formato HATS. Como o DES DR2 é o nosso catálogo \"esquerdo\", não precisamos gerar um cache de margem para ele.\n",
    "\n",
    "Convertendo os dados para o formato hats (**DESCOMENTE A ÚLTIMA LINHA PARA RODAR O PIPELINE**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ad2ee-8949-4012-8b97-8c7c32abc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_args = ImportArguments(\n",
    "    sort_columns=\"coadd_object_id\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    input_path=DES_DIR,\n",
    "    file_reader=\"parquet\",\n",
    "    output_artifact_name=DES_HATS_NAME,\n",
    "    output_path=HATS_DIR,\n",
    "    pixel_threshold=30_000,\n",
    ")\n",
    "\n",
    "### RUN THE PIPELINE (it will fail if the HATS catalog already exists) \n",
    "pipeline_with_client(des_args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8cbcf-feb2-4760-a836-7561754fa2fe",
   "metadata": {},
   "source": [
    "Fazendo o plot dos pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aa20a-7c4e-4507-adac-4a15b53eaa1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the HATS catalog metadata, it does not load any data, just healpix pixels and other metadata\n",
    "des_hats_catalog = hats.read_hats(DES_HATS_DIR)\n",
    "plot_pixels(des_hats_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67564fde-747c-4d57-a8c5-3706ab71eb0d",
   "metadata": {},
   "source": [
    "# Utilizando o LSDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b3a51-d012-485c-843b-ad8b29a91829",
   "metadata": {},
   "source": [
    "\"A biblioteca LSDB é um *framework* que facilita e permite a análise espacial rápida de catálogos astronômicos extremamente grandes (ou seja, consulta e cruzamento de O(1B) fontes). Ela visa abordar os desafios do processamento de dados em larga escala, em particular aqueles levantados pelo LSST.\n",
    "\n",
    "Construída sobre o Dask para escalar e paralelizar operações de forma eficiente em vários *dask workers*, ela aproveita o formato de dados HATS para levantamentos em uma estrutura particionada HEALPix.\" ([LSDB Docs](https://lsdb.readthedocs.io/en/stable/index.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9b7b6-be67-453e-a817-35828230172a",
   "metadata": {},
   "source": [
    "## Instalação do LSDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51898e75-2d9d-4d73-981a-efb516af084b",
   "metadata": {},
   "source": [
    "A biblioteca LSDB normalmente pode ser instalada via conda ou pip com os comandos:\n",
    "\n",
    "```shell\n",
    "conda install -c conda-forge lsdb\n",
    "```\n",
    "\n",
    "```shell\n",
    "python -m pip install lsdb\n",
    "```\n",
    "\n",
    "Para mais detalhes sobre a instalação, veja a documentação [neste link](https://lsdb.readthedocs.io/en/stable/installation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f979f2-ab77-4684-beb3-ea6dfa180eb2",
   "metadata": {},
   "source": [
    "## X-matching usando o LSDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e951312-bedc-4b50-9dc4-3fab7971b863",
   "metadata": {},
   "source": [
    "Para os passos a seguir, foi utilizado, principalmente, o seguinte exemplo de referência: <br>\n",
    "https://lsdb.readthedocs.io/en/stable/tutorials/pre_executed/des-gaia.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf9624-dfef-4e54-adbd-c975af189d4e",
   "metadata": {},
   "source": [
    "Definimos, a seguir, o nome do diretório que armazenará os dados do crossmatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192e94b-7b62-4ad2-adc9-4b1dfd153b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XMATCH_NAME = \"des_dr2_x_2dflens\"\n",
    "\n",
    "OUTPUT_HATS_DIR = HATS_DIR / XMATCH_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a5a56-dabe-45f4-82b5-955acc961aeb",
   "metadata": {},
   "source": [
    "A seguir, lemos os dados espectroscópicos e fotométricos, previamente salvos no formato hats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c4080-dc75-4b0e-bdd8-f96eca55c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_catalog = lsdb.read_hats(DES_HATS_DIR)\n",
    "\n",
    "_2dflens_catalog = lsdb.read_hats(_2DFLENS_HATS_DIR, margin_cache=_2DFLENS_MARGIN_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52223dd2-6aa8-46e5-87e6-fa067d352042",
   "metadata": {},
   "source": [
    "Agora, vamos planejar o crossmatching utilizando o LSDB, mas ainda não iremos executá-lo. Lembrando, novamente, que há uma diferença entre qual é o catálogo \"direito\" e qual é o \"esquerdo\" no crossmatching, como dito na seção anterior quando elaborarmos o cache de margem para o 2dFLenS. No nosso caso, o DES DR2 será o nosso catálogo \"esquerdo\", e o 2dFLenS o nosso catálogo \"direito\". Assim, usamos o método ```crossmatch``` sobre o catálogo do DES e passamos, como argumento, o catálogo do 2dFLenS. Os demais argumentos são o raio de busca (```radius_arcsec```), em arcsec, o número de objetos vizinhos (```n_neighbors```) que serão encontrados no catálogo da direita para cada objeto no catálogo da esquerda (o padrão é apenas um objeto vizinho, ou seja, o objeto do catálogo direito mais próximo ao objeto em questão no catálogo esquerdo) e os sufixos (```suffixes```) que serão usados para diferenciar os dados de ambos os catálogos nos resultados do crossmatching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27cc0b-013e-4fc0-89eb-0a8ecf610d7b",
   "metadata": {},
   "source": [
    "Uma observação importante é que o **raio do crossmatching (radius_arcsec) não pode ser maior que o margin_threshold do cache de margem** do catálogo direito, senão o lsdb exibe um erro:\n",
    "```bash\n",
    "ValueError: Cross match radius is greater than margin threshold.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae258ea-babf-4262-98e0-5547a4784c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatched = des_catalog.crossmatch(\n",
    "    _2dflens_catalog,\n",
    "    # Up to 1 arcsec distance, it is the default\n",
    "    radius_arcsec=2.0,\n",
    "    # Single closest object, it is the default\n",
    "    n_neighbors=1,\n",
    "    # Default would be to use names of the HATS catalogs\n",
    "    suffixes=(\"_des\", \"_2dflens\"),\n",
    ")\n",
    "\n",
    "display(des_catalog)\n",
    "display(_2dflens_catalog)\n",
    "display(xmatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240fe4e-e5b2-43ae-bc1b-5d7b1629b68c",
   "metadata": {},
   "source": [
    "Agora, vamos executar o pipeline do crossmatching utilizando o cliente Dask (**DESCOMENTE A LINHA PARA RODAR O PIPELINE**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e0741-d78c-464a-b461-cf2c8e96202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline with Dask client, it will take a while\n",
    "xmatched.to_hats(OUTPUT_HATS_DIR, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8319b22-c58a-4716-8d6c-163516f67ea4",
   "metadata": {},
   "source": [
    "A seguir, temos as primeiras linhas da tabela contendo os dados do crossmatching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d04d15-7910-481c-bb47-73cf9a11d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the data\n",
    "xmatched_from_disk = lsdb.read_hats(OUTPUT_HATS_DIR)\n",
    "xmatched_from_disk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9150dc4-561a-45bb-95a1-a4feb0697ef5",
   "metadata": {},
   "source": [
    "Podemos obter também a estatística básica dos dados da tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415b06e-86dc-4754-be70-46843255e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = xmatched_from_disk.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b495e-1273-404d-975e-fe430e4282a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd92ec-e3d3-4bdc-8b1f-865770361b03",
   "metadata": {},
   "source": [
    "## Análise dos resultados do X-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375156c3-a8c3-47e0-acd5-6a9fa5722558",
   "metadata": {},
   "source": [
    "A seguir, vamos selecionar uma região do céu delimitada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad32ab-4da6-4273-8580-031ce7d22f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"R.A. min: {ra_min}\")\n",
    "print(f\"R.A. max: {ra_max}\")\n",
    "print(f\"DEC min: {dec_min}\")\n",
    "print(f\"DEC max: {dec_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6c9d5-3abd-47b5-924b-cb25918b5c32",
   "metadata": {},
   "source": [
    "Para isso, podemos usar o método ```polygon_search``` do LSDB para selecionar essa região de interesse nos catálogos, e depois executar o cálculo com o ```.compute()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db408e-d0f8-4652-b79f-ed6df4a07c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polygon_coords = [[ra_min, dec_max], [ra_max, dec_max], [ra_max, dec_min], [ra_min, dec_min]]\n",
    "\n",
    "des_box = des_catalog.polygon_search(polygon_coords).compute()\n",
    "_2dflens_box = _2dflens_catalog.polygon_search(polygon_coords).compute()\n",
    "xmatch_box = xmatched.polygon_search(polygon_coords).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08bf60-e947-407d-8da3-a225c23b722f",
   "metadata": {},
   "source": [
    "Convertemos, então, as coordenadas R.A. para o intervalo $(-180^{\\circ}, 180^{\\circ}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e4e5c-892e-4d95-a22c-28dd03e0ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_des = np.where(des_box[\"ra\"] > 180, des_box[\"ra\"] - 360, des_box[\"ra\"])\n",
    "ra_2dflens = np.where(_2dflens_box[\"ra\"] > 180, _2dflens_box[\"ra\"] - 360, _2dflens_box[\"ra\"])\n",
    "ra_x_2dflens = np.where(xmatch_box[\"ra_2dflens\"] > 180, xmatch_box[\"ra_2dflens\"] - 360, xmatch_box[\"ra_2dflens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae7bb9-e215-4dc1-9ffd-e40dbae564c8",
   "metadata": {},
   "source": [
    "Finalmente, montamos o plot. Nesse plot, os dados do DES são representados por pontos azuis, os dados do 2dFLenS por pontos verdes e os objetos do 2dFLenS que obtiveram uma correspondência a algum objeto do DES no crossmatching estão marcados em vermelho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb78511-4f78-4c47-a1aa-8b0e84dbd680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(ra_des, des_box[\"dec\"], s=2, alpha=0.01, marker=\"+\", color=\"blue\", label=\"DES\")\n",
    "plt.scatter(ra_2dflens, _2dflens_box[\"dec\"], s=50, alpha=0.7, color=\"green\", label=\"2dflens\")\n",
    "plt.scatter(ra_x_2dflens, xmatch_box[\"dec_2dflens\"], s=10, alpha=0.8, color=\"red\", label=\"x-matched\")\n",
    "plt.xlabel(\"R.A. (deg)\")\n",
    "plt.ylabel(\"DEC (deg)\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6de88a-212f-4e20-b36c-90dd11265a9f",
   "metadata": {},
   "source": [
    "Podemos fazer também um gráfico com o Holoviews exibindo apenas os objetos do DES que obtiveram uma correspondência a algum objeto do 2dFLenS no crossmatching. O interessante desse gráfico é que podemos interagir com ele, utilizando, por exemplo, a ferramenta Hover para obter as coordenadas R.A. e DEC de um determinado objeto e a distância dele ao objeto do 2dFLenS com o qual ele foi associado no crossmatching. Adicionamos, ainda, uma barra de cor que indica a distância dos objetos do DES ao seu correpondente do 2dFLenS, de acordo com o crossmatching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae5e2d-7355-447e-ac6e-38c70be9373e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar o gráfico 2D\n",
    "points = hv.Points(df, kdims=['ra_des', 'dec_des'], vdims=['_dist_arcsec'])\n",
    "\n",
    "# Configurar a coloração e ajustar o tamanho dos labels dos eixos\n",
    "points.opts(\n",
    "    width=750, height=500, \n",
    "    color='_dist_arcsec', cmap='Viridis', colorbar=False, tools=['hover'], \n",
    "    size=8, \n",
    "    xlabel='RA (deg)', ylabel='DEC (deg)',\n",
    "    fontsize={'xticks': 12, 'yticks': 12, 'xlabel': 14, 'ylabel': 14}\n",
    ")\n",
    "\n",
    "# Renderizar o gráfico\n",
    "plot = hv.render(points)\n",
    "\n",
    "# Personalizar o ColorBar\n",
    "color_mapper = LinearColorMapper(palette=Viridis256, low=df['_dist_arcsec'].min(), high=df['_dist_arcsec'].max())\n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=12, location=(0,0), title='Dist. (Arcsec)')\n",
    "color_bar.title_text_font_size = '14pt'\n",
    "color_bar.major_label_text_font_size = '12pt'\n",
    "\n",
    "# Adicionar o color bar ao layout do plot\n",
    "plot.add_layout(color_bar, 'right')\n",
    "\n",
    "# Mostrar o gráfico\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fab4ab-f422-4b7d-a1d9-a416a0fdc1d1",
   "metadata": {},
   "source": [
    "Podemos também checar se existem objetos de 2dFLenS que foram associados a mais de um objeto do DES, por causa do cache de margem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0db872-9408-4a53-a99d-748b709da210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_duplicates = df[df.duplicated(subset=['ra_2dflens'])]\n",
    "df_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48b820-e991-4b0c-b46e-c80e5144fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_duplicates.empty:\n",
    "    for i in np.arange(0,len(df_duplicates),1):\n",
    "        id_duplicate = df_duplicates['index_2dflens'].values[i]\n",
    "        print(f\"ID do objeto do 2dFLenS: {id_duplicate}\")\n",
    "        print(f\"ID dos objetos do DES associados a esse mesmo objeto do 2dFLenS: {df[df['index_2dflens'] == id_duplicate]['coadd_object_id_des'].tolist()}\")\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f4006-5178-4826-a7f4-f6b2bbe840e7",
   "metadata": {},
   "source": [
    "Além disso, podemos fazer também o histograma das distâncias de separação dos objetos do crossmatching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a027645-d905-4137-b93e-17f547f665c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertendo a coluna _dist_arcsec para um array numpy.\n",
    "df['_dist_arcsec'] = df['_dist_arcsec'].to_numpy()\n",
    "\n",
    "# Criar um Dataset a partir do DataFrame\n",
    "dataset = hv.Dataset(df, kdims='_dist_arcsec')\n",
    "\n",
    "# Aplicar a operação de histograma\n",
    "hist = hv.operation.histogram(dataset, dimension='_dist_arcsec', normed=False, bins=20)\n",
    "\n",
    "# Personalizar o histograma\n",
    "hist.opts(\n",
    "    xlabel='Distância (arcsec)',\n",
    "    ylabel='Frequência',\n",
    "    title='Histograma das distâncias de separação',\n",
    "    color='blue',\n",
    "    tools=['hover'],\n",
    "    width=750,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Mostrar o histograma\n",
    "hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsdb_env",
   "language": "python",
   "name": "lsdb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
